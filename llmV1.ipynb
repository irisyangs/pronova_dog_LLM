{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pronova LLM V1 #\n",
    "## Use this notebook to do the following ##\n",
    "- Create Qdrant collections\n",
    "- Chunk text files into smaller chunks\n",
    "- Create embeddings for data chunks and querys\n",
    "- Delete qdrant vectors\n",
    "- Run the current model on a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load require librarys\n",
    "import os\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Qdrant connection ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to Qdrant\n"
     ]
    }
   ],
   "source": [
    "# Get the Qdrant API key from the environment variable\n",
    "Qdrant_api_key = os.getenv('Qdrant_API_KEY')\n",
    "if not Qdrant_api_key:\n",
    "    raise ValueError(\"No Qdrant API key found in environment variables\")\n",
    "Qdrant_url = os.getenv('Qdrant_URL')\n",
    "if not Qdrant_url:\n",
    "    raise ValueError(\"No Qdrant URL found in environment variables\")\n",
    "\n",
    "\n",
    "# Initialize Qdrant client\n",
    "try:\n",
    "    Qclient = QdrantClient(\n",
    "        url= Qdrant_url,\n",
    "        api_key=Qdrant_api_key\n",
    "    )\n",
    "    print(\"Successfully connected to Qdrant\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect to Qdrant: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup OpenAI connection ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the OpenAI API key from the environment variable\n",
    "OpenAI_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not OpenAI_api_key:\n",
    "    raise ValueError(\"No OpenAI API key found in environment variables\")\n",
    "\n",
    "OpenAI.api_key = OpenAI_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Qdrant Collection (function) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create collection\n",
    "def create_qdrant_collection(collection_name):\n",
    "    try:\n",
    "        Qclient.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE),\n",
    "        )\n",
    "        print(f\"Collection '{collection_name}' created successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create collection '{collection_name}': {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an OpenAI embedding from a text segment (Function) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the embedding of a text\n",
    "def get_embedding(text):\n",
    "    client = OpenAI()\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        input=text\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn a file into chunks (Function) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read a text file and chunk its content\n",
    "def chunk_text_from_file(file_path, chunk_size=400):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get embedding from a list of chunks (Function) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get embeddings for a list of text chunks\n",
    "def get_embeddings_for_chunks(chunks):\n",
    "    embeddings = []\n",
    "    for chunk in chunks:\n",
    "        embedding = get_embedding(chunk)\n",
    "        embeddings.append(embedding)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsert lists of documents to Qdrant (Function) ###\n",
    "#### Mind the parameters ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to upsert embeddings into Qdrant\n",
    "def upsert_embeddings(collection_name, embeddings, chunks):\n",
    "    points = []\n",
    "    for i, embedding in enumerate(embeddings):\n",
    "        points.append(\n",
    "            {\n",
    "                \"id\": i,\n",
    "                \"vector\": embeddings[i],\n",
    "                \"payload\": {\"text\": chunks[i]}\n",
    "            }\n",
    "        )\n",
    "    try:\n",
    "        Qclient.upsert(\n",
    "            collection_name=collection_name,\n",
    "            points=points\n",
    "        )\n",
    "        print(\"Embeddings upserted successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to upsert embeddings: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve similar chunks from query (Function) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_chunks(collection_name, query, top_k=5):\n",
    "    query_embedding = get_embedding(query)\n",
    "    \n",
    "    search_result = Qclient.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_embedding,\n",
    "        limit=top_k\n",
    "    )\n",
    "\n",
    "    return [result.payload[\"text\"] for result in search_result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Response from Query (Function) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(collection_name, query):\n",
    "    context = retrieve_relevant_chunks(collection_name, query)\n",
    "    system_role = \"You are a specialized assistant that only provides advice on dog-related veterinary care. If a user asks about any other animal or topic outside of dog health, politely decline to answer and remind them that you only provide information about dogs. If you don't know the answer to a question, let the user know that you're not sure and suggest that they consult a veterinarian for more information.\"\n",
    "\n",
    "    # Combine retrieved chunks into a single string\n",
    "    context_text = \"\\n\".join(context)\n",
    "\n",
    "    # Generate a response using GPT-4\n",
    "    client = OpenAI()\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_role},\n",
    "            {\"role\": \"user\", \"content\": \"context\" + context_text},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete all entries in a collection (Function) ###\n",
    "*BE CAREFUL WITH THIS*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_collection(collection_name):\n",
    "    confirmation = input(\"Type 'DELETE' to confirm deletion of entries in \" + collection_name + \". This cannot be undone. Type anything else to abort\")\n",
    "    if confirmation == \"DELETE\" :\n",
    "        try:\n",
    "            Qclient.delete_collection(collection_name=collection_name)\n",
    "            print(f\"Collection '{collection_name}' deleted successfully\")\n",
    "            create_qdrant_collection(collection_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete collection '{collection_name}': {e}\")\n",
    "            raise\n",
    "    else:\n",
    "        print(\"Deletion aborted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markdown Print Function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_markdown(md_text):\n",
    "    display(Markdown(md_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground ##\n",
    "Use this section to test functions and play around with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1 of 726: Skin_Cancer_in_Dogs.txt\n",
      "Processing file 2 of 726: Meningitis_Meningoencephalitis_Meningomyelitis_in_Dogs.txt\n",
      "Processing file 3 of 726: Anaphylaxis_in_Dogs.txt\n",
      "Processing file 4 of 726: How_to_Get_Rid_of_Tapeworms_in_Dogs.txt\n",
      "Processing file 5 of 726: Vascular_Ring_Anomalies_in_Dogs.txt\n",
      "Processing file 6 of 726: Nasal_Dermatoses_in_Dogs_(Dog_Nose_Skin_Issues).txt\n",
      "Processing file 7 of 726: Dog_Pneumonia.txt\n",
      "Processing file 8 of 726: Glucose_in_the_Urine_in_Dogs.txt\n",
      "Processing file 9 of 726: Lupus_in_Dogs.txt\n",
      "Processing file 10 of 726: Progressive_Retinal_Atrophy_(PRA)_In_Dogs.txt\n",
      "Processing file 11 of 726: Calcium_Deposits_in_the_Urinary_Tract_in_Dogs.txt\n",
      "Processing file 12 of 726: Bacterial_Infection_(Campylobacteriosis)_in_Dogs.txt\n",
      "Processing file 13 of 726: Gallstones_in_Dogs.txt\n",
      "Processing file 14 of 726: Dog_Dementia_Symptoms_Causes_Treatment_and_Life_Expectancy.txt\n",
      "Processing file 15 of 726: Eyelid_Protrusion_(Cherry_Eye)_in_Dogs.txt\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'scrapingDemo/ScrapedFiles/Eyelid_Protrusion_(Cherry_Eye)_in_Dogs.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_files\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Chunk the file\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[43mchunk_text_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Get embeddings for the chunks\u001b[39;00m\n\u001b[1;32m     22\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m get_embeddings_for_chunks(chunks)\n",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m, in \u001b[0;36mchunk_text_from_file\u001b[0;34m(file_path, chunk_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchunk_text_from_file\u001b[39m(file_path, chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      4\u001b[0m         text \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [text[i:i \u001b[38;5;241m+\u001b[39m chunk_size] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(text), chunk_size)]\n",
      "File \u001b[0;32m~/environments/rag_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'scrapingDemo/ScrapedFiles/Eyelid_Protrusion_(Cherry_Eye)_in_Dogs.txt'"
     ]
    }
   ],
   "source": [
    "# Define the folder paths\n",
    "scraping_demo_folder = 'scrapingDemo'\n",
    "scraped_files_folder = os.path.join(scraping_demo_folder, 'ScrapedFiles_petMD')\n",
    "\n",
    "#numbver of files in the folder\n",
    "num_files = len([name for name in os.listdir(scraped_files_folder) if os.path.isfile(os.path.join(scraped_files_folder, name))])\n",
    "current_file = 1\n",
    "\n",
    "# Initialize lists to hold all embeddings and chunks\n",
    "all_embeddings = []\n",
    "all_chunks = []\n",
    "\n",
    "# Iterate through each file in the Scraped Files folder\n",
    "for filename in os.listdir(scraped_files_folder):\n",
    "    file_path = os.path.join(scraped_files_folder, filename)\n",
    "    print(f\"Processing file {current_file} of {num_files}: {filename}\")\n",
    "    \n",
    "    # Chunk the file\n",
    "    chunks = chunk_text_from_file(file_path)\n",
    "    \n",
    "    # Get embeddings for the chunks\n",
    "    embeddings = get_embeddings_for_chunks(chunks)\n",
    "    \n",
    "    # Append the embeddings and chunks to the lists\n",
    "    all_embeddings.extend(embeddings)\n",
    "    all_chunks.extend(chunks)\n",
    "    current_file += 1\n",
    "\n",
    "\n",
    "# Upsert the embeddings to the database\n",
    "print(\"Upserting...\")\n",
    "collection_name = 'LLM_V1'  # Define your collection name\n",
    "upsert_embeddings(collection_name, all_embeddings, all_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant chunks:['rinarians.', 'nd insights from our veterinarians.', 'arians.', 'mage:\\xa0iStock.com/Image Source\\nWRITTEN BY\\nVeterinarian\\nDr. Ellen Malmanger is originally from Arkansas, but attended Iowa State University College of Veterinary Medicine for veterinary school....\\nWas this article helpful?\\nSign up for weekly pet health tips and insights from our veterinarians.', \"ary Consult: Canine and Feline. Lippincott Williams & Wilkins; 2005\\n“Veterinary Information Network®, Inc.” VIN.com, 29 June 2005, www.vin.com.\\n\\n\\nWRITTEN BY\\nVeterinarian\\nDr. Lauren Jones graduated from the University of Pennsylvania School of Veterinary Medicine in 2010, after receiving her bachelor's degree...\\nWas this article helpful?\\nSign up for weekly pet health tips and insights from our vete\"]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I provide information based on general knowledge and guidelines related to dog health and veterinary care. If you have a specific question about dog health, I would be happy to help! For detailed or case-specific inquiries, it's always best to consult a veterinarian directly."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"What source is your information based on?\"\n",
    "relevant_chunks = retrieve_relevant_chunks(\"LLM_V1\", query)\n",
    "print(\"Relevant chunks:\" + str(relevant_chunks))\n",
    "print_markdown(generate_response(\"LLM_V1\", query).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'LLM_V1' deleted successfully\n",
      "Collection 'LLM_V1' created successfully\n"
     ]
    }
   ],
   "source": [
    "delete_collection(\"LLM_V1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
