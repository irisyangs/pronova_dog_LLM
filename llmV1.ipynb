{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pronova LLM V1 #\n",
    "## Use this notebook to do the following ##\n",
    "- Create Qdrant collections\n",
    "- Chunk text files into smaller chunks\n",
    "- Create embeddings for data chunks and querys\n",
    "- Delete qdrant vectors\n",
    "- Run the current model on a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load require librarys\n",
    "import os\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Qdrant connection ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to Qdrant\n"
     ]
    }
   ],
   "source": [
    "# Get the Qdrant API key from the environment variable\n",
    "Qdrant_api_key = os.getenv('Qdrant_API_KEY')\n",
    "if not Qdrant_api_key:\n",
    "    raise ValueError(\"No Qdrant API key found in environment variables\")\n",
    "Qdrant_url = os.getenv('Qdrant_URL')\n",
    "if not Qdrant_url:\n",
    "    raise ValueError(\"No Qdrant URL found in environment variables\")\n",
    "\n",
    "\n",
    "# Initialize Qdrant client\n",
    "try:\n",
    "    Qclient = QdrantClient(\n",
    "        url= Qdrant_url,\n",
    "        api_key=Qdrant_api_key\n",
    "    )\n",
    "    print(\"Successfully connected to Qdrant\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect to Qdrant: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup OpenAI connection ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the OpenAI API key from the environment variable\n",
    "OpenAI_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not OpenAI_api_key:\n",
    "    raise ValueError(\"No OpenAI API key found in environment variables\")\n",
    "\n",
    "OpenAI.api_key = OpenAI_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Qdrant Collection (function) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create collection\n",
    "def create_qdrant_collection(collection_name):\n",
    "    try:\n",
    "        Qclient.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE),\n",
    "        )\n",
    "        print(f\"Collection '{collection_name}' created successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create collection '{collection_name}': {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an OpenAI embedding from a text segment (Function) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the embedding of a text\n",
    "def get_embedding(text):\n",
    "    client = OpenAI()\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        input=text\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn a file into chunks (Function) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read a text file and chunk its content\n",
    "def chunk_text_from_file(file_path, chunk_size=400):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get embedding from a list of chunks (Function) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get embeddings for a list of text chunks\n",
    "def get_embeddings_for_chunks(chunks):\n",
    "    embeddings = []\n",
    "    for chunk in chunks:\n",
    "        embedding = get_embedding(chunk)\n",
    "        embeddings.append(embedding)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get largest Qdrant ID (function) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qdrant_next_id(collection_name):\n",
    "    try:\n",
    "        collection = Qclient.get_collection(collection_name=collection_name)\n",
    "        id = collection.points_count\n",
    "        if id == None:\n",
    "            print(\"id was zero\")\n",
    "            return 0\n",
    "        else:\n",
    "            print(f\"Next ID in collection '{collection_name}' is {id}\")\n",
    "            return id\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get next ID from collection '{collection_name}': {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsert lists of documents to Qdrant (Function) ###\n",
    "#### Mind the parameters ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to upsert embeddings into Qdrant\n",
    "# def upsert_embeddings(collection_name, embeddings, chunks):\n",
    "def upsert_embeddings(collection_name, embeddings, chunks, filename):\n",
    "    largest_id = get_qdrant_next_id(collection_name)\n",
    "    points = []\n",
    "    for i in range(len(embeddings)):\n",
    "        points.append(\n",
    "            {\n",
    "                \"id\": i + largest_id + 1,\n",
    "                \"vector\": embeddings[i],\n",
    "                \"payload\": {\n",
    "                    \"text\": chunks[i],   # Attach the chunk as payload\n",
    "                    \"source_file\": filename  # Add source file\n",
    "                }            \n",
    "            }\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        Qclient.upsert(\n",
    "            collection_name=collection_name,\n",
    "            points=points\n",
    "        )\n",
    "        print(\"Embeddings upserted successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to upsert embeddings: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve similar chunks from query (Function) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_chunks(collection_name, query, top_k=10):\n",
    "    query_embedding = get_embedding(query)\n",
    "    \n",
    "    search_result = Qclient.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_embedding,\n",
    "        limit=top_k\n",
    "    )\n",
    "\n",
    "    contexts = [result.payload[\"text\"] for result in search_result]\n",
    "    files = [result.payload.get(\"source_file\") for result in search_result]\n",
    "    \n",
    "    return contexts, files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Response from Query (Function) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_response(collection_name, query):\n",
    "    context, files = retrieve_relevant_chunks(collection_name, query)\n",
    "    unique_files = np.unique(files)\n",
    "\n",
    "    system_role = \"You are a specialized assistant that only provides advice on dog-related veterinary care. If a user asks about any other animal or topic outside of dog health, politely decline to answer and remind them that you only provide information about dogs.\"\n",
    "\n",
    "    # If you don't know the answer to a question, let the user know that you're not sure and suggest that they consult a veterinarian for more information.\n",
    "\n",
    "    # Combine retrieved chunks into a single string\n",
    "    context_text = \"\\n\".join(context)\n",
    "\n",
    "    # Generate a response using GPT-4\n",
    "    client = OpenAI()\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_role},\n",
    "            {\"role\": \"user\", \"content\": \"context\" + context_text},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message, unique_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete all entries in a collection (Function) ###\n",
    "*BE CAREFUL WITH THIS*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_collection(collection_name):\n",
    "    confirmation = input(\"Type 'DELETE' to confirm deletion of entries in \" + collection_name + \". This cannot be undone. Type anything else to abort\")\n",
    "    if confirmation == \"DELETE\" :\n",
    "        try:\n",
    "            Qclient.delete_collection(collection_name=collection_name)\n",
    "            print(f\"Collection '{collection_name}' deleted successfully\")\n",
    "            create_qdrant_collection(collection_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete collection '{collection_name}': {e}\")\n",
    "            raise\n",
    "    else:\n",
    "        print(\"Deletion aborted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markdown Print Function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_markdown(md_text):\n",
    "    display(Markdown(md_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Files From Folder (function) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files_from_folder(collection_name, file_path, limit):\n",
    "    \n",
    "    #number of files in the folder \n",
    "    num_files = len([name for name in os.listdir(file_path) if os.path.isfile(os.path.join(file_path, name))])\n",
    "    if limit == None:\n",
    "        limit = num_files\n",
    "    current_file = 1\n",
    "\n",
    "    for filename in os.listdir(file_path):\n",
    "        if current_file > limit:\n",
    "            break\n",
    "        curr_file_path = os.path.join(file_path, filename)\n",
    "        print(f\"Processing file {current_file} of {limit}: {filename}\")\n",
    "        \n",
    "        # # Chunk the file\n",
    "        chunks = chunk_text_from_file(curr_file_path)\n",
    "        # Get embeddings for the chunks\n",
    "        embeddings = get_embeddings_for_chunks(chunks)\n",
    "        # Upsert the embeddings into Qdrant\n",
    "        upsert_embeddings(collection_name, embeddings, chunks, filename)\n",
    "        current_file += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground ##\n",
    "Use this section to test functions and play around with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'LLM_V1' deleted successfully\n",
      "Collection 'LLM_V1' created successfully\n",
      "Processing file 1 of 14: How_To_Help_a_Dog_With_Separation_Anxiety.txt\n",
      "Next ID in collection 'LLM_V1' is 0\n",
      "Embeddings upserted successfully\n",
      "Processing file 2 of 14: How_To_Start_Training_Your_Puppy.txt\n",
      "Next ID in collection 'LLM_V1' is 21\n",
      "Embeddings upserted successfully\n",
      "Processing file 3 of 14: How_to_Teach_a_Dog_to_Come_to_You_in_Any_Environment.txt\n",
      "Next ID in collection 'LLM_V1' is 40\n",
      "Embeddings upserted successfully\n",
      "Processing file 4 of 14: Obedience_Training_for_Dogs_4_Easy_Cues_to_Master.txt\n",
      "Next ID in collection 'LLM_V1' is 54\n",
      "Embeddings upserted successfully\n",
      "Processing file 5 of 14: How_To_Leash_Train_a_Dog.txt\n",
      "Next ID in collection 'LLM_V1' is 71\n",
      "Embeddings upserted successfully\n",
      "Processing file 6 of 14: Why_Do_Dogs_Stretch_When_They_Greet_You.txt\n",
      "Next ID in collection 'LLM_V1' is 93\n",
      "Embeddings upserted successfully\n",
      "Processing file 7 of 14: Why_Do_Dogs_Look_at_You_When_They_Poop.txt\n",
      "Next ID in collection 'LLM_V1' is 101\n",
      "Embeddings upserted successfully\n",
      "Processing file 8 of 14: Why_Do_Dogs_Bring_You_Their_Toys_to_Greet_You.txt\n",
      "Next ID in collection 'LLM_V1' is 116\n",
      "Embeddings upserted successfully\n",
      "Processing file 9 of 14: How_To_Keep_Dogs_off_the_Couch_and_Other_Furniture.txt\n",
      "Next ID in collection 'LLM_V1' is 126\n",
      "Embeddings upserted successfully\n",
      "Processing file 10 of 14: How_To_Stop_a_Dog_From_Barking.txt\n",
      "Next ID in collection 'LLM_V1' is 141\n",
      "Embeddings upserted successfully\n",
      "Processing file 11 of 14: Dog_Pooping_in_the_House_Why_It's_Happening_and_What_To_Do.txt\n",
      "Next ID in collection 'LLM_V1' is 160\n",
      "Embeddings upserted successfully\n",
      "Processing file 12 of 14: How_To_Introduce_Dogs_to_Each_Other.txt\n",
      "Next ID in collection 'LLM_V1' is 181\n",
      "Embeddings upserted successfully\n",
      "Processing file 13 of 14: Why_Do_Dogs_Get_the_Zoomies.txt\n",
      "Next ID in collection 'LLM_V1' is 194\n",
      "Embeddings upserted successfully\n",
      "Processing file 14 of 14: Why_Is_My_Dog_Shaking.txt\n",
      "Next ID in collection 'LLM_V1' is 209\n",
      "Embeddings upserted successfully\n"
     ]
    }
   ],
   "source": [
    "filepath = \"scrapingDemo/ScrapedFiles_petMD_behavior\"\n",
    "collection_name = \"LLM_V1\"\n",
    "limit = None\n",
    "delete_collection(collection_name)\n",
    "process_files_from_folder(collection_name, filepath, limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Common symptoms of pollen allergies in dogs can include:\n",
       "\n",
       "1. **Itchy Skin:** Dogs may scratch, lick, or bite their skin, especially in areas like the paws, face, ears, and belly.\n",
       "2. **Red or Inflamed Skin:** You may notice redness, rashes, or hot spots on your dog’s skin.\n",
       "3. **Ear Infections:** Chronic inflammation in the ears or repetitive shaking of the head may indicate an ear infection related to allergies.\n",
       "4. **Sneezing and Nasal Discharge:** Similar to humans, dogs can exhibit sneezing or a runny nose.\n",
       "5. **Watery Eyes:** You might see excessive tearing or redness in the eyes.\n",
       "\n",
       "For treatment, it’s essential to consult with your veterinarian for a proper diagnosis and to rule out other potential causes of your dog's symptoms. Treatment options may include:\n",
       "\n",
       "- **Antihistamines:** Your vet may recommend over-the-counter or prescription antihistamines to help alleviate symptoms.\n",
       "- **Corticosteroids:** In more severe cases, corticosteroids may be prescribed to reduce inflammation and itching.\n",
       "- **Omega-3 Fatty Acids:** Supplements may help improve skin health and reduce inflammation.\n",
       "- **Regular Bathing:** Bathing your dog with a hypoallergenic shampoo can help remove allergens from their skin and coat.\n",
       "- **Allergy Testing:** In some cases, allergy tests may be suggested to identify the specific allergens affecting your dog.\n",
       "\n",
       "Always consult with your veterinarian for tailored advice and treatment options based on your dog's specific needs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files used: \n",
      "\n",
      "Dog_Pooping_in_the_House_Why_It's_Happening_and_What_To_Do.txt\n",
      "How_To_Help_a_Dog_With_Separation_Anxiety.txt\n",
      "Why_Do_Dogs_Get_the_Zoomies.txt\n",
      "Why_Is_My_Dog_Shaking.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"I think my dog has a pollen allergy. What are the symptoms and how can I treat it?\"\n",
    "\n",
    "response, files = generate_response(\"LLM_V1\", query)\n",
    "print_markdown(response.content)\n",
    "\n",
    "print(\"files used: \\n\")\n",
    "for file in files:\n",
    "    print(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
